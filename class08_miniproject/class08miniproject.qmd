---
title: "Class 08 Mini Project"
author: "Kiana Bohanon (PID: A18702316)"
format: pdf
toc: TRUE
---
## Background

In today's class we will apply the methods and techniques clustering and PCA to help make sense of a real world breast cancer **FNA (fine needle aspirations)** biopsy data set.

## Data Import

We start by importing our data. It is a CSV file, so we will use the `read.csv()` function. First, download the file containing the data, and place it in the project for this class on your computer. 

```{r}
#read.csv("WisconsinCancer.csv")
```
```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names=1)
```
```{r}
head(wisc.df, 4)
```
Omit the first column of `diagnosis` because I don't want to use this for my machine learning models. We will use it later on to compare our results to the expert diagnosis:
```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]

# Create diagnosis vector for later 
diagnosis <- wisc.df$diagnosis
```

## Exploratory Data Analysis

**Q1.** How many observations are in this dataset?
```{r}
nrow(wisc.data)
```
569 observations are in this dataset.

**Q2.** How many of the observations have a malignant diagnosis?
```{r}
# Use the table() function:
#table(diagnosis)
table(diagnosis)["M"]
```
212 observations have a malignant diagnosis.

**Q3.** How many variables/features in the data are suffixed with `_mean`?
```{r}
#colnames(wisc.data)
length(grep("_mean", colnames(wisc.data)))
```
There are 10 variables/features in the data suffixed with `_mean`.

## Principal Component Analysis

The main function here is `prcomp()` and we want to make sure we set the optional argument `scale=TRUE`:
We will need to check if the data needs to be scaled before performing PCA by looking at the mean and standard deviation.
```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```
**Q4.** From your results, what proportion of the original variance is captured by the first principal component (PC1)?

44.27%.

**Q5.** How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

Three PCs are required to describe at least 70% of the original variance.

**Q6.** How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

Seven PCs are required to describe at least 90% of the original variance. 

Our main PCA "score plot" or "PC plot" of results:
```{r}
library(ggplot2)
```
```{r}
ggplot(wisc.pr$x) + aes(PC1,PC2, col=diagnosis) + geom_point()
```
Biplot:
```{r}
biplot(wisc.pr)
```

**Q7.** What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is very confusing and not easy to understand. A lot of the data is on top of each other and you can't really tell anything or come to a conclusion easily.

Similar ggplot for PC1 and PC3:
```{r}
ggplot(wisc.pr$x) + aes(PC1,PC3, col=diagnosis) + geom_point()
```

**Q8.** Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

These plots are a lot easier to interpret and you can easily tell where the trends are. The data is organized much nicer as well. 

## Variance Explained

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```
```{r}
# Variance explained by each principal component: pve
pve <- wisc.pr$sdev^2 / sum(wisc.pr$sdev^2)

# Plot variance explained for each principal component
plot(c(1,pve), xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


## Communicating PCA Results

**Q9.** For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC. Are there any features with larger contributions than this one?

```{r}
wisc.pr$rotation["concave.points_mean", 1]
sort(abs(wisc.pr$rotation[, 1]), decreasing = TRUE)[1:5]
```
No, there are not any features with larger contributions than this one.

## Hierarchical Clustering

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
```

Creating the cluster deprogram:
```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```
**Q10.** Using the `plot()` and `abline()` functions, what is the height at which the clustering model has 4 clusters?

The height where the clustering model has 4 clusters is at 19. 

## Selecting number of clusters

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```
 
**Q12.** Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The ward.D2 method gives the best results because it minimizes within-cluster variance, producing compact and well-separated clusters. Compared to single, complete, and average linkage, ward.D2 avoids chaining and creates clusters that better reflect the underlying structure of the data.

## Combining Methods

Here we will take our PCA results and use those as input for clustering. In other words our `wisc.pr$x` scores that we plotted above (the main output from PCA - how the data lie on our new principal component axis/variables) and use a subset of the PCs as input for `hclust()`.

```{r}
pc.dist <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(pc.dist, method="ward.D2")
plot(wisc.pr.hclust)
```

Cut the dendrogram/tree into two main groups/clusters:
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```
**Q13.**How well does the newly created hclust model with two clusters separate out the two “M” and “B” diagnoses?

I want to know how clustering into `grps` with values of 1 or 2 correspond to the expert `diagnosis`.
```{r}
table(grps, diagnosis)
```

My clustering **group 1** are mostly "M" diagnosis (179) and my clustering **group 2** are mostly "B" diagnosis.

24 False positives
179 True positives
333 True negatives
33 False negatives

**Q14.** How well do the hierarchical clustering models you created in the previous sections (i.e. without first doing PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.hclust.clusters and wisc.pr.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
```
These models do fairly well in terms of separating the diagnosis, as the numbers are fairly similar. 

## Prediction
```{r}
url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

**Q16.** Which of these new patients should we prioritize for follow up based on your results?

We should prioritize Patient 2 because their results are more similar to the malignant plots than Patient 1, so it is more likely that they may have malignant cancer cells. 
